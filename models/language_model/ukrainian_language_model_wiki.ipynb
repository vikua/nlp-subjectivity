{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "import re\n",
    "import html\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tokenize_uk\n",
    "\n",
    "from fastai.text import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/ukwiki'\n",
    "\n",
    "lm_files = [] \n",
    "for d in os.listdir(path):\n",
    "    wiki_files = os.listdir(os.path.join(path, d))\n",
    "    for f in wiki_files: \n",
    "        lm_files.append(os.path.join(path, d, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files: 2116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../data/ukwiki/AV/wiki_11',\n",
       " '../../data/ukwiki/AV/wiki_10',\n",
       " '../../data/ukwiki/AV/wiki_03',\n",
       " '../../data/ukwiki/AV/wiki_04',\n",
       " '../../data/ukwiki/AV/wiki_05',\n",
       " '../../data/ukwiki/AV/wiki_02',\n",
       " '../../data/ukwiki/AV/wiki_15',\n",
       " '../../data/ukwiki/AV/wiki_12',\n",
       " '../../data/ukwiki/AV/wiki_13',\n",
       " '../../data/ukwiki/AV/wiki_14']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Num files:', len(lm_files))\n",
    "lm_files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for i in lm_files:\n",
    "    with open(i) as f:\n",
    "        for line in f:\n",
    "            texts.append(json.loads(line))\n",
    "        \n",
    "texts = pd.DataFrame(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2705951</td>\n",
       "      <td>ГЕС Алматті I, II\\n\\nГЕС Алматті I, II — гідро...</td>\n",
       "      <td>ГЕС Алматті I, II</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2705954</td>\n",
       "      <td>Цифровий відбиток пристрою\\n\\nЦифровий відбито...</td>\n",
       "      <td>Цифровий відбиток пристрою</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2705955</td>\n",
       "      <td>Наїзд фургона на натовп у Торонто (2018)\\n\\nО ...</td>\n",
       "      <td>Наїзд фургона на натовп у Торонто (2018)</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2705963</td>\n",
       "      <td>Бавер Лідія Миколаївна\\n\\nЛі́дія Микола́ївна Б...</td>\n",
       "      <td>Бавер Лідія Миколаївна</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2705966</td>\n",
       "      <td>360 Total Security\\n\\n360 Total Security — ком...</td>\n",
       "      <td>360 Total Security</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0  2705951  ГЕС Алматті I, II\\n\\nГЕС Алматті I, II — гідро...   \n",
       "1  2705954  Цифровий відбиток пристрою\\n\\nЦифровий відбито...   \n",
       "2  2705955  Наїзд фургона на натовп у Торонто (2018)\\n\\nО ...   \n",
       "3  2705963  Бавер Лідія Миколаївна\\n\\nЛі́дія Микола́ївна Б...   \n",
       "4  2705966  360 Total Security\\n\\n360 Total Security — ком...   \n",
       "\n",
       "                                      title  \\\n",
       "0                         ГЕС Алматті I, II   \n",
       "1                Цифровий відбиток пристрою   \n",
       "2  Наїзд фургона на натовп у Торонто (2018)   \n",
       "3                    Бавер Лідія Миколаївна   \n",
       "4                        360 Total Security   \n",
       "\n",
       "                                           url  \n",
       "0  https://uk.wikipedia.org/wiki?curid=2705951  \n",
       "1  https://uk.wikipedia.org/wiki?curid=2705954  \n",
       "2  https://uk.wikipedia.org/wiki?curid=2705955  \n",
       "3  https://uk.wikipedia.org/wiki?curid=2705963  \n",
       "4  https://uk.wikipedia.org/wiki?curid=2705966  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_title_from_text(text):\n",
    "    words = text.split(\"\\n\\n\")\n",
    "    if len(words) >= 2:\n",
    "        return ''.join(words[1:])\n",
    "    else:\n",
    "        return ''.join(words)\n",
    "    \n",
    "texts['text'] = texts['text'].apply(lambda x: split_title_from_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2705951</td>\n",
       "      <td>ГЕС Алматті I, II — гідроелектростанції на пів...</td>\n",
       "      <td>ГЕС Алматті I, II</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2705954</td>\n",
       "      <td>Цифровий відбиток пристрою (англ. fingerprint ...</td>\n",
       "      <td>Цифровий відбиток пристрою</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2705955</td>\n",
       "      <td>О 13:30 (UTC -4:00), 23 квітня 2018, арендован...</td>\n",
       "      <td>Наїзд фургона на натовп у Торонто (2018)</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2705963</td>\n",
       "      <td>Лі́дія Микола́ївна Ба́вер ( м. Онєга, Архангел...</td>\n",
       "      <td>Бавер Лідія Миколаївна</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2705966</td>\n",
       "      <td>360 Total Security — комплексний антивірусний ...</td>\n",
       "      <td>360 Total Security</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0  2705951  ГЕС Алматті I, II — гідроелектростанції на пів...   \n",
       "1  2705954  Цифровий відбиток пристрою (англ. fingerprint ...   \n",
       "2  2705955  О 13:30 (UTC -4:00), 23 квітня 2018, арендован...   \n",
       "3  2705963  Лі́дія Микола́ївна Ба́вер ( м. Онєга, Архангел...   \n",
       "4  2705966  360 Total Security — комплексний антивірусний ...   \n",
       "\n",
       "                                      title  \\\n",
       "0                         ГЕС Алматті I, II   \n",
       "1                Цифровий відбиток пристрою   \n",
       "2  Наїзд фургона на натовп у Торонто (2018)   \n",
       "3                    Бавер Лідія Миколаївна   \n",
       "4                        360 Total Security   \n",
       "\n",
       "                                           url  \n",
       "0  https://uk.wikipedia.org/wiki?curid=2705951  \n",
       "1  https://uk.wikipedia.org/wiki?curid=2705954  \n",
       "2  https://uk.wikipedia.org/wiki?curid=2705955  \n",
       "3  https://uk.wikipedia.org/wiki?curid=2705963  \n",
       "4  https://uk.wikipedia.org/wiki?curid=2705966  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784390, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2705951</td>\n",
       "      <td>ГЕС Алматті I, II — гідроелектростанції на пів...</td>\n",
       "      <td>ГЕС Алматті I, II</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2705954</td>\n",
       "      <td>Цифровий відбиток пристрою (англ. fingerprint ...</td>\n",
       "      <td>Цифровий відбиток пристрою</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2705955</td>\n",
       "      <td>О 13:30 (UTC -4:00), 23 квітня 2018, арендован...</td>\n",
       "      <td>Наїзд фургона на натовп у Торонто (2018)</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2705963</td>\n",
       "      <td>Лі́дія Микола́ївна Ба́вер ( м. Онєга, Архангел...</td>\n",
       "      <td>Бавер Лідія Миколаївна</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2705966</td>\n",
       "      <td>360 Total Security — комплексний антивірусний ...</td>\n",
       "      <td>360 Total Security</td>\n",
       "      <td>https://uk.wikipedia.org/wiki?curid=2705966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0  2705951  ГЕС Алматті I, II — гідроелектростанції на пів...   \n",
       "1  2705954  Цифровий відбиток пристрою (англ. fingerprint ...   \n",
       "2  2705955  О 13:30 (UTC -4:00), 23 квітня 2018, арендован...   \n",
       "3  2705963  Лі́дія Микола́ївна Ба́вер ( м. Онєга, Архангел...   \n",
       "4  2705966  360 Total Security — комплексний антивірусний ...   \n",
       "\n",
       "                                      title  \\\n",
       "0                         ГЕС Алматті I, II   \n",
       "1                Цифровий відбиток пристрою   \n",
       "2  Наїзд фургона на натовп у Торонто (2018)   \n",
       "3                    Бавер Лідія Миколаївна   \n",
       "4                        360 Total Security   \n",
       "\n",
       "                                           url  \n",
       "0  https://uk.wikipedia.org/wiki?curid=2705951  \n",
       "1  https://uk.wikipedia.org/wiki?curid=2705954  \n",
       "2  https://uk.wikipedia.org/wiki?curid=2705955  \n",
       "3  https://uk.wikipedia.org/wiki?curid=2705963  \n",
       "4  https://uk.wikipedia.org/wiki?curid=2705966  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### limit corpus to 100 million of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts['labels'] = 0\n",
    "texts = texts[['labels', 'text']]\n",
    "texts['len'] = texts['text'].apply(lambda x: len(tokenize_uk.tokenize_words(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = texts[texts['len'] > 600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72728, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts = train_test_split(texts, test_size=0.1, random_state=1234, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts[['labels', 'text']].to_csv('../../data/train.csv', header=False, index=False)\n",
    "val_texts[['labels', 'text']].to_csv('../../data/val.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UKTokenizer():\n",
    "    def __init__(self):\n",
    "        self.re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "\n",
    "    def sub_br(self,x): \n",
    "        return self.re_br.sub(\"\\n\", x)\n",
    "\n",
    "    def tokenize(self, x): \n",
    "        return tokenize_uk.tokenize_words(self.sub_br(x))\n",
    "\n",
    "    re_rep = re.compile(r'(\\S)(\\1{3,})')\n",
    "    re_word_rep = re.compile(r'(\\b\\w+\\W+)(\\1{3,})')\n",
    "\n",
    "    @staticmethod\n",
    "    def replace_rep(m):\n",
    "        TK_REP = 'tk_rep'\n",
    "        c,cc = m.groups()\n",
    "        return f' {TK_REP} {len(cc)+1} {c} '\n",
    "\n",
    "    @staticmethod\n",
    "    def replace_wrep(m):\n",
    "        TK_WREP = 'tk_wrep'\n",
    "        c,cc = m.groups()\n",
    "        return f' {TK_WREP} {len(cc.split())+1} {c} '\n",
    "\n",
    "    @staticmethod\n",
    "    def do_caps(ss):\n",
    "        TOK_UP,TOK_SENT,TOK_MIX = ' t_up ',' t_st ',' t_mx '\n",
    "        res = []\n",
    "        prev='.'\n",
    "        re_word = re.compile('\\w')\n",
    "        re_nonsp = re.compile('\\S')\n",
    "        for s in re.findall(r'\\w+|\\W+', ss):\n",
    "            res += ([TOK_UP,s.lower()] if (s.isupper() and (len(s)>2))\n",
    "    #                 else [TOK_SENT,s.lower()] if (s.istitle() and re_word.search(prev))\n",
    "                    else [s.lower()])\n",
    "    #         if re_nonsp.search(s): prev = s\n",
    "        return ''.join(res)\n",
    "\n",
    "    def proc_text(self, s):\n",
    "        s = self.re_rep.sub(UKTokenizer.replace_rep, s)\n",
    "        s = self.re_word_rep.sub(UKTokenizer.replace_wrep, s)\n",
    "        s = UKTokenizer.do_caps(s)\n",
    "        s = re.sub(r'([/#])', r' \\1 ', s)\n",
    "        s = re.sub(' {2,}', ' ', s)\n",
    "        return self.tokenize(s)\n",
    "\n",
    "    @staticmethod\n",
    "    def proc_all(ss):\n",
    "        tok = UKTokenizer()\n",
    "        return [tok.proc_text(s) for s in ss]\n",
    "\n",
    "    @staticmethod\n",
    "    def proc_all_mp(ss):\n",
    "        ncpus = num_cpus()//2\n",
    "        with ProcessPoolExecutor(ncpus) as e:\n",
    "            return sum(e.map(UKTokenizer.proc_all, ss), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "\n",
    "def get_texts(df, n_lbls=1):\n",
    "    labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)): texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    texts = texts.apply(fixup).values.astype(str)\n",
    "\n",
    "    tok = UKTokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    return tok, list(labels)\n",
    "\n",
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_, labels_ = get_texts(r, n_lbls)\n",
    "        tok += tok_;\n",
    "        labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=10000\n",
    "train_texts = pd.read_csv('../../data/train.csv', header=None, chunksize=chunksize)\n",
    "val_texts = pd.read_csv('../../data/val.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(train_texts, 1)\n",
    "tok_val, val_lables = get_all(val_texts, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 6055767),\n",
       " ('.', 5475994),\n",
       " ('в', 1648059),\n",
       " ('і', 1460758),\n",
       " ('у', 1387202),\n",
       " ('на', 1250826),\n",
       " ('з', 1153768),\n",
       " (')', 965364),\n",
       " ('(', 957776),\n",
       " ('«', 902154),\n",
       " ('»', 899536),\n",
       " ('-', 816885),\n",
       " ('—', 788103),\n",
       " ('та', 766387),\n",
       " ('до', 684830),\n",
       " ('t_up', 607450),\n",
       " ('\"', 584384),\n",
       " ('що', 574805),\n",
       " ('за', 434976),\n",
       " ('року', 419553),\n",
       " ('не', 380220),\n",
       " (':', 347002),\n",
       " ('а', 331484),\n",
       " ('для', 329646),\n",
       " ('як', 284788)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in tok_trn for p in o)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2\n",
    "\n",
    "itos = [o for o, c in freq.most_common(max_vocab) if c>min_freq] # getting rid of the rare words\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../data/trn_ids.npy', trn_lm)\n",
    "np.save('../../data/val_ids.npy', val_lm)\n",
    "with open('../../data/itos.pkl', 'wb') as f:\n",
    "    pickle.dump(itos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 65455)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs=len(itos)\n",
    "vs,len(trn_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 400,1150,3\n",
    "\n",
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=52\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "\n",
    "model_path = '../../bin/uk_lm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "md = LanguageModelData(model_path, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.clip = 0.2\n",
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "lrs = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(lrs/2, 1, wds=wd, use_clr=(32,2), cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm_ukrainian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
